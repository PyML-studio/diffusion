{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class LinearNoiseScheduler():\n",
    "    def __init__(self, num_steps, beta_start, beta_end):\n",
    "        self.num_steps = num_steps\n",
    "        self.beta_start = beta_start\n",
    "        self.beta_end = beta_end\n",
    "        self.step = 0\n",
    "\n",
    "        # pre-compute alphas and betas\n",
    "        self.betas = torch.linspace(beta_start, beta_end, num_steps)\n",
    "        self.alphas = 1 - self.betas\n",
    "        # \\bar{\\alpha}_t}\n",
    "        self.alpha_cum_prod = torch.cumprod(self.alphas, 0)\n",
    "        # \\sqrt{\\bar{\\alpha}_t}}\n",
    "        self.sqrt_alpha_cum_prod = torch.sqrt(self.alpha_cum_prod)\n",
    "        # \\sqrt{1-\\bar{\\alpha}_t}}\n",
    "        self.sqrt_one_minus_alpha_cum_prod = torch.sqrt(1 - self.alpha_cum_prod)\n",
    "\n",
    "    # forward process\n",
    "    def add_noise(self, original, noise, t):\n",
    "        original_shape = original.shape\n",
    "        batch_size = original_shape[0]\n",
    "\n",
    "        sqrt_alph_cum_prod = self.sqrt_alpha_cum_prod[t].repeat(batch_size, 1)\n",
    "        sqrt_one_minus_alpha_cum_prod = self.sqrt_one_minus_alpha_cum_prod[t].repeat(batch_size, 1)\n",
    "\n",
    "        for _ in range(original.dim() - 1):\n",
    "            sqrt_alph_cum_prod = sqrt_alph_cum_prod.unsqueeze(-1)\n",
    "            sqrt_one_minus_alpha_cum_prod = sqrt_one_minus_alpha_cum_prod.unsqueeze(-1)\n",
    "\n",
    "        # \\sqrt{\\bar{\\alpha}_t}} * x_0 + (1-\\sqrt{\\bar{\\alpha}_t}) * \\epsilon_t\n",
    "        return sqrt_alph_cum_prod * original + sqrt_one_minus_alpha_cum_prod * noise\n",
    "    \n",
    "    def sample_prev_timestep(self, xt, noise_pred, t):\n",
    "        # x0 = (xt - \\sqrt{1-\\bar{\\alpha}_t}} * \\epsilon_t) / \\sqrt{\\bar{\\alpha}_t}}\n",
    "        x0 = (\n",
    "            xt - self.sqrt_one_minus_alpha_cum_prod[t] * noise_pred\n",
    "        ) / self.sqrt_alpha_cum_prod[t]\n",
    "\n",
    "        x0 = torch.clamp(x0, -1, 1)\n",
    "\n",
    "        mean = xt - (self.betas[t] * noise_pred) / self.sqrt_one_minus_alpha_cum_prod[t]\n",
    "        mean = mean / torch.sqrt(self.alphas[t])\n",
    "\n",
    "        if t == 0:\n",
    "            return mean, x0\n",
    "\n",
    "        variance = (1 - self.alpha_cum_prod[t-1]) / (1 - self.alpha_cum_prod[t])\n",
    "        variance *= self.betas[t]\n",
    "        sigma = torch.sqrt(variance)\n",
    "        # sample from Gaussian distribution\n",
    "        z = torch.randn(xt.shape).to(xt.device)\n",
    "        return mean + sigma * z, x0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNet model\n",
    "\n",
    " * Using sinusoidal position embedding for time-embeddings\n",
    "\n",
    "$$sin\\left(pos / 10000^{2i / d_{model}}\\right)$$\n",
    "$$cos\\left(pos / 10000^{2i+1 / d_{model}}\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def get_time_embedding(time_steps, t_emb_dim):\n",
    "    device = time_steps.device\n",
    "    factor = 10000 ** ((\n",
    "        torch.arange(0, t_emb_dim//2, device=device) / (t_emb_dim // 2)\n",
    "    ))\n",
    "\n",
    "    t_emb = time_steps.unsqueeze(-1).repeat(1, t_emb_dim//2) / factor\n",
    "    t_emb = torch.cat([torch.sin(t_emb), torch.cos(t_emb)], dim=-1)\n",
    "\n",
    "    return t_emb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Down-block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownBlock(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            t_emb_dim,\n",
    "            down_sample,\n",
    "            num_heads\n",
    "        ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.down_sample = down_sample\n",
    "        self.resnet_conv_first = nn.Sequential(\n",
    "            nn.GroupNorm(8, in_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels, out_channels, 3, 1, 1)\n",
    "        )\n",
    "\n",
    "        self.t_emb_layers = nn.Sequential(\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(t_emb_dim, out_channels),\n",
    "        )\n",
    "\n",
    "        self.resnet_conv_second = nn.Sequential(\n",
    "            nn.GroupNorm(8, out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1)\n",
    "        )\n",
    "\n",
    "        self.attn_norm = nn.GroupNorm(8, out_channels)\n",
    "        self.attn = nn.MultiheadAttention(\n",
    "            out_channels, num_heads, batch_first=True\n",
    "        )\n",
    "        self.resid_input_conv = nn.Conv2d(in_channels, out_channels, 1)\n",
    "        self.down_sample_conv = nn.Conv2d(\n",
    "            out_channels, out_channels, 4, 2, 1\n",
    "        ) if self.down_sample else nn.Identity()\n",
    "\n",
    "    def forward(self, x, t_emb):\n",
    "        out = x\n",
    "        # ResNet block 1\n",
    "        resnet_input = out\n",
    "        out = self.resnet_conv_first(out)\n",
    "        # time embedding\n",
    "        out += self.t_emb_layers(t_emb).unsqueeze(-1).unsqueeze(-1)\n",
    "        # ResNet block 2\n",
    "        out = self.resnet_conv_second(out)\n",
    "        # residual\n",
    "        out += self.resid_input_conv(resnet_input)\n",
    "\n",
    "        # self-attention block\n",
    "        B, C, H, W = out.shape\n",
    "        input_for_attn = out.view(B, C, -1)\n",
    "        input_for_attn = self.attn_norm(input_for_attn)\n",
    "        input_for_attn = input_for_attn.transpose(1, 2)\n",
    "        out_attn, _ = self.attn(input_for_attn, input_for_attn, input_for_attn)\n",
    "        out_attn = out_attn.transpose(1, 2).view(B, C, H, W)\n",
    "        out += out_attn\n",
    "\n",
    "        out = self.down_sample_conv(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mid-Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MidBlock(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            t_emb_dim,\n",
    "            num_heads\n",
    "        ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.resnet_conv_first = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.GroupNorm(8, in_channels),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(in_channels, out_channels, 3, 1, 1)\n",
    "            ),\n",
    "            nn.Sequential(\n",
    "                nn.GroupNorm(8, out_channels),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(out_channels, out_channels, 3, 1, 1)\n",
    "            )\n",
    "        ])\n",
    "\n",
    "        self.t_emb_layers = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.SiLU(),\n",
    "                nn.Linear(t_emb_dim, out_channels),\n",
    "            ),\n",
    "            nn.Sequential(\n",
    "                nn.SiLU(),\n",
    "                nn.Linear(t_emb_dim, out_channels),\n",
    "            )\n",
    "        ])\n",
    "\n",
    "        self.resnet_conv_second = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.GroupNorm(8, out_channels),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(out_channels, out_channels, 3, 1, 1)\n",
    "            ),\n",
    "            nn.Sequential(\n",
    "                nn.GroupNorm(8, out_channels),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(out_channels, out_channels, 3, 1, 1)\n",
    "            )\n",
    "        ])\n",
    "\n",
    "        self.attn_norm = nn.GroupNorm(8, out_channels)\n",
    "        self.attn = nn.MultiheadAttention(\n",
    "            out_channels, num_heads, batch_first=True\n",
    "        )\n",
    "        self.resid_input_conv = nn.ModuleList([\n",
    "            nn.Conv2d(in_channels, out_channels, 1),\n",
    "            nn.Conv2d(out_channels, out_channels, 1)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x, t_emb):\n",
    "        out = x\n",
    "        # First ResNet block\n",
    "        resnet_input = out\n",
    "        out = self.resnet_conv_first[0](out)\n",
    "        out += self.t_emb_layers[0](t_emb).unsqueeze(-1).unsqueeze(-1)\n",
    "        out = self.resnet_conv_second[0](out)\n",
    "        out += self.resid_input_conv[0](resnet_input)\n",
    "\n",
    "        # self-attention block\n",
    "        B, C, H, W = out.shape\n",
    "        input_for_attn = out.view(B, C, -1)\n",
    "        input_for_attn = self.attn_norm(input_for_attn)\n",
    "        input_for_attn = input_for_attn.transpose(1, 2)\n",
    "        out_attn, _ = self.attn(input_for_attn, input_for_attn, input_for_attn)\n",
    "        out_attn = out_attn.transpose(1, 2).view(B, C, H, W)\n",
    "        out += out_attn\n",
    "\n",
    "        # Second ResNet block\n",
    "        resnet_input = out\n",
    "        out = self.resnet_conv_first[1](out)\n",
    "        out += self.t_emb_layers[1](t_emb).unsqueeze(-1).unsqueeze(-1)\n",
    "        out = self.resnet_conv_second[1](out)\n",
    "        out += self.resid_input_conv[1](resnet_input)\n",
    "\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upsample-Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpBlock(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            t_emb_dim,\n",
    "            up_sample,\n",
    "            num_heads\n",
    "        ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.up_sample = up_sample\n",
    "        self.resnet_conv_first = nn.Sequential(\n",
    "            nn.GroupNorm(8, in_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels, out_channels, 3, 1, 1)\n",
    "        )\n",
    "\n",
    "        self.t_emb_layers = nn.Sequential(\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(t_emb_dim, out_channels),\n",
    "        )\n",
    "\n",
    "        self.resnet_conv_second = nn.Sequential(\n",
    "            nn.GroupNorm(8, out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1)\n",
    "        )\n",
    "\n",
    "        self.attn_norm = nn.GroupNorm(8, out_channels)\n",
    "        self.attn = nn.MultiheadAttention(\n",
    "            out_channels, num_heads, batch_first=True\n",
    "        )\n",
    "        self.resid_input_conv = nn.Conv2d(in_channels, out_channels, 1)\n",
    "        self.up_sample_conv = nn.ConvTranspose2d(\n",
    "            in_channels // 2, in_channels // 2, 4, 2, 1\n",
    "        ) if self.up_sample else nn.Identity()\n",
    "\n",
    "    def forward(self, x, out_down, t_emb):\n",
    "        x = self.up_sample_conv(x)\n",
    "        x = torch.cat([x, out_down], dim=1)\n",
    "\n",
    "        # ResNet block\n",
    "        out = x\n",
    "        resnet_input = out\n",
    "        out = self.resnet_conv_first(out)\n",
    "        out += self.t_emb_layers(t_emb).unsqueeze(-1).unsqueeze(-1)\n",
    "        out = self.resnet_conv_second(out)\n",
    "        out += self.resid_input_conv(resnet_input)\n",
    "\n",
    "        # self-attention block\n",
    "        B, C, H, W = out.shape\n",
    "        input_for_attn = out.view(B, C, -1)\n",
    "        input_for_attn = self.attn_norm(input_for_attn)\n",
    "        input_for_attn = input_for_attn.transpose(1, 2)\n",
    "        out_attn, _ = self.attn(input_for_attn, input_for_attn, input_for_attn)\n",
    "        out_attn = out_attn.transpose(1, 2).view(B, C, H, W)\n",
    "        out += out_attn\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting everything together in UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, img_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.down_channels = [32, 64, 128, 256]\n",
    "        self.mid_channels = [256, 256, 128]\n",
    "        self.t_emb_dim = 128\n",
    "\n",
    "        self.down_samples = [True, True, False]\n",
    "        self.up_samples = list(reversed(self.down_samples))\n",
    "\n",
    "        self.t_proj = nn.Sequential(\n",
    "            nn.Linear(self.t_emb_dim, self.t_emb_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(self.t_emb_dim, self.t_emb_dim),\n",
    "        )\n",
    "        self.conv_inp_layer = nn.Conv2d(img_channels, self.down_channels[0], 3, 1, 1)\n",
    "\n",
    "        self.downs = nn.ModuleList([])\n",
    "        for i in range(len(self.down_channels) - 1):\n",
    "            self.downs.append(\n",
    "                DownBlock(\n",
    "                    self.down_channels[i],\n",
    "                    self.down_channels[i+1],\n",
    "                    self.t_emb_dim,\n",
    "                    down_sample=self.down_samples[i],\n",
    "                    num_heads=4\n",
    "                )\n",
    "            )\n",
    "\n",
    "        self.mids = nn.ModuleList([])\n",
    "        for i in range(len(self.mid_channels)-1):\n",
    "            self.mids.append(\n",
    "                MidBlock(\n",
    "                    self.down_channels[i],\n",
    "                    self.mid_channels[i+1],\n",
    "                    self.t_emb_dim,\n",
    "                    num_heads=4\n",
    "                )\n",
    "            )\n",
    "\n",
    "        self.ups = nn.ModuleList([])\n",
    "        for i in range(len(self.down_channels)-1):\n",
    "            self.ups.append(\n",
    "                UpBlock(\n",
    "                    self.down_channels[i] * 2,\n",
    "                    self.down_channels[i-1] if i != 0 else 16,\n",
    "                    self.t_emb_dim,\n",
    "                    up_sample=self.up_samples[i],\n",
    "                    num_heads=4\n",
    "                )\n",
    "            )\n",
    "\n",
    "        self.norm_out = nn.GroupNorm(8, 16)\n",
    "        self.conv_out = nn.Conv2d(16, img_channels, 3, 1, 1)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        t_emb = get_time_embedding(t, self.t_emb_dim)\n",
    "        t_emb = self.t_proj(t_emb)\n",
    "\n",
    "        out = self.conv_inp_layer(x)\n",
    "        out_downs = []\n",
    "        for down_layer in self.downs:\n",
    "            print(\"Down:\", out.shape)\n",
    "            out_downs.append(out)\n",
    "            out = down_layer(out, t_emb)\n",
    "\n",
    "        for mid_layer in self.mids:\n",
    "            print(\"Mid:\", out.shape)\n",
    "            out = mid_layer(out, t_emb)\n",
    "\n",
    "        for up_layer in self.ups:\n",
    "            print(\"Up:\", out.shape)\n",
    "            out = up_layer(out, out_downs.pop(), t_emb)\n",
    "\n",
    "        out = self.norm_out(out)\n",
    "        out = nn.SiLU()(out)\n",
    "        out = self.conv_out(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-1.), tensor(1.))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "# scale the pixels to the range [-1, 1]\n",
    "def scale(x):\n",
    "    return x * 2 - 1\n",
    "\n",
    "def unscale(x):\n",
    "    return (x + 1) / 2\n",
    "\n",
    "mnist = MNIST(\n",
    "    root=\"data\",\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "\n",
    "class MNISTDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, _ = self.dataset[idx]\n",
    "        img = scale(img)\n",
    "        return img\n",
    "    \n",
    "# testing:\n",
    "dataset = MNISTDataset(mnist)\n",
    "next(iter(dataset))[0].min(), next(iter(dataset))[0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
