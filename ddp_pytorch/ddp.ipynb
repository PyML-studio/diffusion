{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class LinearNoiseScheduler():\n",
    "    def __init__(self, num_steps, beta_start, beta_end):\n",
    "        self.num_steps = num_steps\n",
    "        self.beta_start = beta_start\n",
    "        self.beta_end = beta_end\n",
    "        self.step = 0\n",
    "\n",
    "        # pre-compute alphas and betas\n",
    "        self.betas = torch.linspace(beta_start, beta_end, num_steps)\n",
    "        self.alphas = 1 - self.betas\n",
    "        # \\bar{\\alpha}_t}\n",
    "        self.alpha_cum_prod = torch.cumprod(self.alphas, 0)\n",
    "        # \\sqrt{\\bar{\\alpha}_t}}\n",
    "        self.sqrt_alpha_cum_prod = torch.sqrt(self.alpha_cum_prod)\n",
    "        # \\sqrt{1-\\bar{\\alpha}_t}}\n",
    "        self.sqrt_one_minus_alpha_cum_prod = torch.sqrt(1 - self.alpha_cum_prod)\n",
    "\n",
    "    # forward process\n",
    "    def add_noise(self, original, noise, t):\n",
    "        original_shape = original.shape\n",
    "        batch_size = original_shape[0]\n",
    "\n",
    "        sqrt_alph_cum_prod = self.sqrt_alpha_cum_prod[t].repeat(batch_size, 1)\n",
    "        sqrt_one_minus_alpha_cum_prod = self.sqrt_one_minus_alpha_cum_prod[t].repeat(batch_size, 1)\n",
    "\n",
    "        for _ in range(original.dim() - 1):\n",
    "            sqrt_alph_cum_prod = sqrt_alph_cum_prod.unsqueeze(-1)\n",
    "            sqrt_one_minus_alpha_cum_prod = sqrt_one_minus_alpha_cum_prod.unsqueeze(-1)\n",
    "\n",
    "        # \\sqrt{\\bar{\\alpha}_t}} * x_0 + (1-\\sqrt{\\bar{\\alpha}_t}) * \\epsilon_t\n",
    "        return sqrt_alph_cum_prod * original + sqrt_one_minus_alpha_cum_prod * noise\n",
    "    \n",
    "    def sample_prev_timestep(self, xt, noise_pred, t):\n",
    "        # x0 = (xt - \\sqrt{1-\\bar{\\alpha}_t}} * \\epsilon_t) / \\sqrt{\\bar{\\alpha}_t}}\n",
    "        x0 = (\n",
    "            xt - self.sqrt_one_minus_alpha_cum_prod[t] * noise_pred\n",
    "        ) / self.sqrt_alpha_cum_prod[t]\n",
    "\n",
    "        x0 = torch.clamp(x0, -1, 1)\n",
    "\n",
    "        mean = xt - (self.betas[t] * noise_pred) / self.sqrt_one_minus_alpha_cum_prod[t]\n",
    "        mean = mean / torch.sqrt(self.alphas[t])\n",
    "\n",
    "        if t == 0:\n",
    "            return mean, x0\n",
    "\n",
    "        variance = (1 - self.alpha_cum_prod[t-1]) / (1 - self.alpha_cum_prod[t])\n",
    "        variance *= self.betas[t]\n",
    "        sigma = torch.sqrt(variance)\n",
    "        # sample from Gaussian distribution\n",
    "        z = torch.randn(xt.shape).to(xt.device)\n",
    "        return mean + sigma * z, x0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNet model\n",
    "\n",
    " * Using sinusoidal position embedding for time-embeddings\n",
    "\n",
    "$$sin\\left(pos / 10000^{2i / d_{model}}\\right)$$\n",
    "$$cos\\left(pos / 10000^{2i+1 / d_{model}}\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def get_time_embedding(time_steps, t_emb_dim):\n",
    "    device = time_steps.device\n",
    "    factor = 10000 ** ((\n",
    "        torch.arange(0, t_emb_dim//2, device=device) / (t_emb_dim // 2)\n",
    "    ))\n",
    "\n",
    "    t_emb = time_steps.unsqueeze(-1).repeat(1, t_emb_dim//2) / factor\n",
    "    t_emb = torch.cat([torch.sin(t_emb), torch.cos(t_emb)], dim=-1)\n",
    "\n",
    "    return t_emb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Down-block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownBlock(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            t_emb_dim,\n",
    "            down_sample,\n",
    "            num_heads\n",
    "        ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.down_sample = down_sample\n",
    "        self.resnet_conv_first = nn.Sequential(\n",
    "            nn.GroupNorm(8, in_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels, out_channels, 3, 1, 1)\n",
    "        )\n",
    "\n",
    "        self.t_emb_layers = nn.Sequential(\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(t_emb_dim, out_channels),\n",
    "        )\n",
    "\n",
    "        self.resnet_conv_second = nn.Sequential(\n",
    "            nn.GroupNorm(8, out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1)\n",
    "        )\n",
    "\n",
    "        self.attn_norm = nn.GroupNorm(8, out_channels)\n",
    "        self.attn = nn.MultiheadAttention(\n",
    "            out_channels, num_heads, batch_first=True\n",
    "        )\n",
    "        self.resid_input_conv = nn.Conv2d(in_channels, out_channels, 1)\n",
    "        self.down_sample_conv = nn.Conv2d(\n",
    "            out_channels, out_channels, 4, 2, 1\n",
    "        ) if self.down_sample else nn.Identity()\n",
    "\n",
    "    def forward(self, x, t_emb):\n",
    "        out = x\n",
    "        # ResNet block 1\n",
    "        resnet_input = out\n",
    "        out = self.resnet_conv_first(out)\n",
    "        # time embedding\n",
    "        out += self.t_emb_layers(t_emb).unsqueeze(-1).unsqueeze(-1)\n",
    "        # ResNet block 2\n",
    "        out = self.resnet_conv_second(out)\n",
    "        # residual\n",
    "        out += self.resid_input_conv(resnet_input)\n",
    "\n",
    "        # self-attention block\n",
    "        B, C, H, W = out.shape\n",
    "        input_for_attn = out.view(B, C, -1)\n",
    "        input_for_attn = self.attn_norm(input_for_attn)\n",
    "        input_for_attn = input_for_attn.transpose(1, 2)\n",
    "        out_attn, _ = self.attn(input_for_attn, input_for_attn, input_for_attn)\n",
    "        out_attn = out_attn.transpose(1, 2).view(B, C, H, W)\n",
    "        out += out_attn\n",
    "\n",
    "        out = self.down_sample_conv(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mid-Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MidBlock(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            t_emb_dim,\n",
    "            num_heads\n",
    "        ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.resnet_conv_first = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.GroupNorm(8, in_channels),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(in_channels, out_channels, 3, 1, 1)\n",
    "            ),\n",
    "            nn.Sequential(\n",
    "                nn.GroupNorm(8, out_channels),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(out_channels, out_channels, 3, 1, 1)\n",
    "            )\n",
    "        ])\n",
    "\n",
    "        self.t_emb_layers = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.SiLU(),\n",
    "                nn.Linear(t_emb_dim, out_channels),\n",
    "            ),\n",
    "            nn.Sequential(\n",
    "                nn.SiLU(),\n",
    "                nn.Linear(t_emb_dim, out_channels),\n",
    "            )\n",
    "        ])\n",
    "\n",
    "        self.resnet_conv_second = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.GroupNorm(8, out_channels),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(out_channels, out_channels, 3, 1, 1)\n",
    "            ),\n",
    "            nn.Sequential(\n",
    "                nn.GroupNorm(8, out_channels),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(out_channels, out_channels, 3, 1, 1)\n",
    "            )\n",
    "        ])\n",
    "\n",
    "        self.attn_norm = nn.GroupNorm(8, out_channels)\n",
    "        self.attn = nn.MultiheadAttention(\n",
    "            out_channels, num_heads, batch_first=True\n",
    "        )\n",
    "        self.resid_input_conv = nn.ModuleList([\n",
    "            nn.Conv2d(in_channels, out_channels, 1),\n",
    "            nn.Conv2d(out_channels, out_channels, 1)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x, t_emb):\n",
    "        out = x\n",
    "        # First ResNet block\n",
    "        resnet_input = out\n",
    "        out = self.resnet_conv_first[0](out)\n",
    "        out += self.t_emb_layers[0](t_emb).unsqueeze(-1).unsqueeze(-1)\n",
    "        out = self.resnet_conv_second[0](out)\n",
    "        out += self.resid_input_conv[0](resnet_input)\n",
    "\n",
    "        # self-attention block\n",
    "        B, C, H, W = out.shape\n",
    "        input_for_attn = out.view(B, C, -1)\n",
    "        input_for_attn = self.attn_norm(input_for_attn)\n",
    "        input_for_attn = input_for_attn.transpose(1, 2)\n",
    "        out_attn, _ = self.attn(input_for_attn, input_for_attn, input_for_attn)\n",
    "        out_attn = out_attn.transpose(1, 2).view(B, C, H, W)\n",
    "        out += out_attn\n",
    "\n",
    "        # Second ResNet block\n",
    "        resnet_input = out\n",
    "        out = self.resnet_conv_first[1](out)\n",
    "        out += self.t_emb_layers[1](t_emb).unsqueeze(-1).unsqueeze(-1)\n",
    "        out = self.resnet_conv_second[1](out)\n",
    "        out += self.resid_input_conv[1](resnet_input)\n",
    "\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Up-Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpBlock(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            t_emb_dim,\n",
    "            up_sample,\n",
    "            num_heads\n",
    "        ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.up_sample = up_sample\n",
    "        self.resnet_conv_first = nn.Sequential(\n",
    "            nn.GroupNorm(8, in_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels, out_channels, 3, 1, 1)\n",
    "        )\n",
    "\n",
    "        self.t_emb_layers = nn.Sequential(\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(t_emb_dim, out_channels),\n",
    "        )\n",
    "\n",
    "        self.resnet_conv_second = nn.Sequential(\n",
    "            nn.GroupNorm(8, out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1)\n",
    "        )\n",
    "\n",
    "        self.attn_norm = nn.GroupNorm(8, out_channels)\n",
    "        self.attn = nn.MultiheadAttention(\n",
    "            out_channels, num_heads, batch_first=True\n",
    "        )\n",
    "        self.resid_input_conv = nn.Conv2d(in_channels, out_channels, 1)\n",
    "        self.up_sample_conv = nn.ConvTranspose2d(\n",
    "            in_channels // 2, in_channels // 2, 4, 2, 1\n",
    "        ) if self.up_sample else nn.Identity()\n",
    "\n",
    "    def forward(self, x, out_down, t_emb):\n",
    "        x = self.up_sample_conv(x)\n",
    "        x = torch.cat([x, out_down], dim=1)\n",
    "\n",
    "        # ResNet block\n",
    "        out = x\n",
    "        resnet_input = out\n",
    "        out = self.resnet_conv_first(out)\n",
    "        out += self.t_emb_layers(t_emb).unsqueeze(-1).unsqueeze(-1)\n",
    "        out = self.resnet_conv_second(out)\n",
    "        out += self.resid_input_conv(resnet_input)\n",
    "\n",
    "        # self-attention block\n",
    "        B, C, H, W = out.shape\n",
    "        input_for_attn = out.view(B, C, -1)\n",
    "        input_for_attn = self.attn_norm(input_for_attn)\n",
    "        input_for_attn = input_for_attn.transpose(1, 2)\n",
    "        out_attn, _ = self.attn(input_for_attn, input_for_attn, input_for_attn)\n",
    "        out_attn = out_attn.transpose(1, 2).view(B, C, H, W)\n",
    "        out += out_attn\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
